{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from others.datasets import get_dataset\n",
    "from models import *\n",
    "import others.bounds as bounds\n",
    "from others.utils_practical import *\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('==========', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainloader, net, epoch, optimizer, scheduler, criterion, writer=None, model_path=\"./checkpoints/\", width_list=[None], new_sedghi=False, lip4conv=False, gouk_correct=False):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    global count_setp\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    batch_idx = -1\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        reg_loss_conv = torch.tensor([0.0], requires_grad=True).to(device=loss.device)\n",
    "        \n",
    "        ############################# lip4conv:\n",
    "        if lip4conv:\n",
    "            for (kernel, input_size) in net.get_all_kernels():\n",
    "                bound = bounds.estimate(\n",
    "                    kernel,\n",
    "                    n=input_size[0],\n",
    "                    name_func=\"ours_backward\",\n",
    "                    n_iter=6,\n",
    "                )\n",
    "                reg_loss_conv = reg_loss_conv + F.threshold(\n",
    "                    bound, 1.0, 0.0\n",
    "                )\n",
    "\n",
    "            reg_loss_conv = 0.1 * reg_loss_conv\n",
    "        #############################\n",
    "\n",
    "        loss = loss + reg_loss_conv\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        ############################# Gouk method:\n",
    "        if gouk_correct and (count_setp > 0 or epoch != 0):# and count_setp % 100 == 0:\n",
    "\n",
    "            with torch.no_grad():\n",
    "                constrain_conv(\n",
    "                    net,\n",
    "                    mode='divide-by-largest',\n",
    "                    conv_clip_assign_value=1,\n",
    "                    linear_clip_assign_value=1,\n",
    "                    iterations=5,\n",
    "                    orthogonal=-1,\n",
    "                    outputs=width_list,\n",
    "                )\n",
    "        #################\n",
    "\n",
    "        ########################## Senderovich (nsedghi):\n",
    "        if new_sedghi and (count_setp > 0 or epoch != 0) and count_setp % 100 == 0:\n",
    "\n",
    "            with torch.no_grad():\n",
    "                constrain_conv(\n",
    "                    net,\n",
    "                    mode='clip',\n",
    "                    conv_clip_assign_value=1,\n",
    "                    linear_clip_assign_value=1,\n",
    "                    orthogonal=-1,\n",
    "                    outputs=width_list,\n",
    "                )\n",
    "        #################\n",
    "\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        count_setp += 1\n",
    "\n",
    "    writer.add_scalar('train/acc', 100.*correct/total, epoch)\n",
    "    writer.add_scalar('train/loss', train_loss/(batch_idx+1), epoch)\n",
    "\n",
    "    print('train/acc', 100.*correct/total)\n",
    "    print('train/loss', train_loss/(batch_idx+1))\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    state = {\n",
    "        'net': net.state_dict(),\n",
    "        'epoch': epoch,\n",
    "        'scheduler': scheduler.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(state, model_path)\n",
    "\n",
    "    return train_loss/(batch_idx+1), 100.*correct/total\n",
    "\n",
    "\n",
    "def test(testloader, net, epoch, criterion, optimizer, scheduler, writer=None, model_path=\"./checkpoints/\"):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    batch_idx = -1\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "            'scheduler': scheduler.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }\n",
    "        torch.save(state, model_path)\n",
    "\n",
    "\n",
    "    writer.add_scalar('test/acc', 100.*correct/total, epoch)\n",
    "    writer.add_scalar('test/loss', test_loss/(batch_idx+1), epoch)\n",
    "\n",
    "    print(' Test acc', 100.*correct/total)\n",
    "\n",
    "    return test_loss/(batch_idx+1), 100.*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(trainloader, testloader, method='fastclip', in_chan=1, kernel_size=3, padding=0, stride=1, dilation=1, padding_mode='zeros', lin_layer=None, outdir = 'simpleConv/', epochs=120):\n",
    "    # lin_layer = 36864 #k5: 36864 #k3: 43264\n",
    "\n",
    "    clip_flag    = False\n",
    "    new_sedghi   = False\n",
    "    miyato_flag  = False\n",
    "    gouk_correct = False\n",
    "    lip4conv     = False\n",
    "    orig_flag    = False\n",
    "\n",
    "    if method[:4] == 'fast':\n",
    "        clip_flag    = True\n",
    "    elif method == 'catclip':\n",
    "        clip_flag    = True\n",
    "    elif method == 'nsedghi':\n",
    "        new_sedghi   = True\n",
    "    elif method == 'miyato':\n",
    "        miyato_flag  = True\n",
    "    elif method == 'gouk':\n",
    "        gouk_correct = True\n",
    "    elif method == 'lip4conv':\n",
    "        lip4conv     = True\n",
    "    elif method == 'orig':\n",
    "        orig_flag    = True\n",
    "    else:\n",
    "        print('unknown method!')\n",
    "        exit(0)\n",
    "\n",
    "    bn_flag = True\n",
    "    kernel_size = kernel_size\n",
    "    stride = stride\n",
    "    padding = padding\n",
    "    dilation = dilation\n",
    "    padding_mode = padding_mode\n",
    "    lin_layer = lin_layer\n",
    "\n",
    "    outdir = outdir + method + '_model_k' + str(kernel_size) + '_p' + str(padding) + '_st' + str(stride) + '_di' + str(dilation) + '_pad_' + padding_mode + '/'\n",
    "\n",
    "    if not os.path.exists(outdir):\n",
    "        os.makedirs(outdir)\n",
    "\n",
    "    print('------------> Output Directory: ', outdir)\n",
    "    writer = SummaryWriter(outdir)\n",
    "\n",
    "    df = None\n",
    "    if miyato_flag:\n",
    "        print('other methods are used!')\n",
    "        net = simpleConv_miyato(in_chan=in_chan, device=device, clip_flag=clip_flag, clip_opt_iter=1, summary=True, bn=bn_flag, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, padding_mode=padding_mode, lin_layer=lin_layer)\n",
    "    elif new_sedghi or gouk_correct or orig_flag or lip4conv:\n",
    "        print('other methods are used!')\n",
    "        net = simpleConv_orig(in_chan=in_chan, device=device, clip_flag=clip_flag, clip_opt_iter=1, summary=True, bn=bn_flag, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, padding_mode=padding_mode, lin_layer=lin_layer) \n",
    "    elif clip_flag:\n",
    "        net = simpleConv(concat_sv=True, in_chan=in_chan, device=device, clip_flag=True, clip_opt_iter=5, summary=True, clip=1., writer=writer, bn=bn_flag, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, padding_mode=padding_mode, lin_layer=lin_layer) \n",
    "\n",
    "    model_path =  outdir + 'ckpt.pth'\n",
    "    model_path_test =  outdir + 'ckpt_best_test.pth'\n",
    "\n",
    "    net = net.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=40, gamma=0.1)\n",
    "\n",
    "    tr_loss_list = []\n",
    "    tr_acc_list = []\n",
    "    ts_loss_list = []\n",
    "    ts_acc_list = []\n",
    "    sv_list = []\n",
    "\n",
    "    conv_outputs = []\n",
    "    if new_sedghi or gouk_correct:\n",
    "        conv_outputs = get_conv_output_shapes(net, (1,28,28))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        tr_loss, tr_acc = train(trainloader, net, epoch, optimizer, scheduler, criterion, writer=writer, model_path=model_path, width_list=conv_outputs, new_sedghi=new_sedghi, lip4conv=lip4conv, gouk_correct=gouk_correct)\n",
    "        ts_loss, ts_acc = test(testloader, net, epoch, criterion, optimizer, scheduler, writer=writer, model_path=model_path_test)\n",
    "\n",
    "        net.zero_grad()\n",
    "        idx = 0\n",
    "        for (m_name, m) in net.named_modules():\n",
    "            if isinstance(m, (torch.nn.Linear, torch.nn.Conv2d)):\n",
    "                if idx > 0:\n",
    "                    continue\n",
    "                VT_shape = [1, 1, 28, 28]\n",
    "                if idx == 1:\n",
    "                    VT_shape = [1, 64, 28, 28]\n",
    "                x0 = torch.randn(VT_shape, device=device)\n",
    "                const = 'Conv2d_' + str(idx)\n",
    "\n",
    "                qr = power_qr(lambda x: m(x) - m(torch.zeros_like(x)), x0.clone().detach(), n_iters=1000, device=device)\n",
    "\n",
    "                writer.add_scalar('train/lsv_' + const, qr[-1][0], epoch)\n",
    "                sv_list.append(qr[-1][0].item())\n",
    "                print('largest SV of ' + const, qr[-1][0].item())\n",
    "                idx += 1\n",
    "\n",
    "\n",
    "        tr_loss_list.append(tr_loss)\n",
    "        tr_acc_list.append(tr_acc)\n",
    "        ts_loss_list.append(ts_loss)\n",
    "        ts_acc_list.append(ts_acc)\n",
    "\n",
    "        writer.add_scalar('test/best_acc', best_acc, epoch)\n",
    "\n",
    "    df = pd.DataFrame({'tr_loss': tr_loss_list, 'tr_acc': tr_acc_list, 'ts_loss': ts_loss_list, 'ts_acc': ts_acc_list, 'SV': sv_list})\n",
    "    df.to_csv(outdir + 'results.csv')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------> Output Directory:  simpleConv/fastclip_model_k3_p1_st1_di1_pad_reflect/\n",
      "cocant sv is being recorded!\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "\n",
      "Epoch: 0\n",
      "train/acc 87.07\n",
      "train/loss 0.403339290828593\n",
      " Test acc 92.97\n",
      "largest SV of Conv2d_0 1.893099069595337\n",
      "\n",
      "Epoch: 1\n",
      "train/acc 92.315\n",
      "train/loss 0.23934928089507354\n",
      " Test acc 94.47\n",
      "largest SV of Conv2d_0 1.2353582382202148\n",
      "\n",
      "Epoch: 2\n",
      "train/acc 93.80166666666666\n",
      "train/loss 0.19593507969684437\n",
      " Test acc 93.57\n",
      "largest SV of Conv2d_0 1.0937789678573608\n",
      "\n",
      "Epoch: 3\n",
      "train/acc 94.37666666666667\n",
      "train/loss 0.17539547415557447\n",
      " Test acc 93.93\n",
      "largest SV of Conv2d_0 1.079450011253357\n",
      "\n",
      "Epoch: 4\n",
      "train/acc 94.71833333333333\n",
      "train/loss 0.1650073821070606\n",
      " Test acc 94.23\n",
      "largest SV of Conv2d_0 1.0809744596481323\n",
      "\n",
      "Epoch: 5\n",
      "train/acc 95.07333333333334\n",
      "train/loss 0.152522298803271\n",
      " Test acc 94.43\n",
      "largest SV of Conv2d_0 1.0693864822387695\n",
      "\n",
      "Epoch: 6\n",
      "train/acc 95.37\n",
      "train/loss 0.14588199107091565\n",
      " Test acc 94.74\n",
      "largest SV of Conv2d_0 1.0780842304229736\n",
      "\n",
      "Epoch: 7\n",
      "train/acc 95.48\n",
      "train/loss 0.13918892999511284\n",
      " Test acc 94.4\n",
      "largest SV of Conv2d_0 1.0714062452316284\n",
      "\n",
      "Epoch: 8\n",
      "train/acc 95.725\n",
      "train/loss 0.13310678261937872\n",
      " Test acc 94.02\n",
      "largest SV of Conv2d_0 1.0754551887512207\n",
      "\n",
      "Epoch: 9\n",
      "train/acc 95.785\n",
      "train/loss 0.13028255435846633\n",
      " Test acc 95.27\n",
      "largest SV of Conv2d_0 1.0786263942718506\n",
      "\n",
      "Epoch: 10\n",
      "train/acc 95.87333333333333\n",
      "train/loss 0.12595967091381677\n",
      " Test acc 94.88\n",
      "largest SV of Conv2d_0 1.0733004808425903\n",
      "\n",
      "Epoch: 11\n",
      "train/acc 96.14666666666666\n",
      "train/loss 0.11919197248719902\n",
      " Test acc 94.76\n",
      "largest SV of Conv2d_0 1.0687570571899414\n",
      "\n",
      "Epoch: 12\n",
      "train/acc 96.20833333333333\n",
      "train/loss 0.11550600340625625\n",
      " Test acc 95.47\n",
      "largest SV of Conv2d_0 1.0794705152511597\n",
      "\n",
      "Epoch: 13\n",
      "train/acc 96.29833333333333\n",
      "train/loss 0.11442598749770284\n",
      " Test acc 95.42\n",
      "largest SV of Conv2d_0 1.0775492191314697\n",
      "\n",
      "Epoch: 14\n",
      "train/acc 96.45\n",
      "train/loss 0.11025276441754563\n",
      " Test acc 94.66\n",
      "largest SV of Conv2d_0 1.076933741569519\n",
      "\n",
      "Epoch: 15\n",
      "train/acc 96.48666666666666\n",
      "train/loss 0.10782242094132818\n",
      " Test acc 94.82\n",
      "largest SV of Conv2d_0 1.0689617395401\n",
      "\n",
      "Epoch: 16\n",
      "train/acc 96.58833333333334\n",
      "train/loss 0.10675839354186806\n",
      " Test acc 95.6\n",
      "largest SV of Conv2d_0 1.0822560787200928\n",
      "\n",
      "Epoch: 17\n",
      "train/acc 96.57833333333333\n",
      "train/loss 0.10438232012251929\n",
      " Test acc 94.2\n",
      "largest SV of Conv2d_0 1.0796010494232178\n",
      "\n",
      "Epoch: 18\n",
      "train/acc 96.59333333333333\n",
      "train/loss 0.1032141028031675\n",
      " Test acc 95.34\n",
      "largest SV of Conv2d_0 1.0764129161834717\n",
      "\n",
      "Epoch: 19\n",
      "train/acc 96.65833333333333\n",
      "train/loss 0.10063578942214757\n",
      " Test acc 94.99\n",
      "largest SV of Conv2d_0 1.080183744430542\n",
      "\n",
      "Epoch: 20\n",
      "train/acc 96.87333333333333\n",
      "train/loss 0.09713262058635637\n",
      " Test acc 94.13\n",
      "largest SV of Conv2d_0 1.0801950693130493\n",
      "\n",
      "Epoch: 21\n",
      "train/acc 96.81666666666666\n",
      "train/loss 0.09647952176646384\n",
      " Test acc 95.08\n",
      "largest SV of Conv2d_0 1.0733360052108765\n",
      "\n",
      "Epoch: 22\n",
      "train/acc 96.95166666666667\n",
      "train/loss 0.09458904289630557\n",
      " Test acc 94.89\n",
      "largest SV of Conv2d_0 1.0827125310897827\n",
      "\n",
      "Epoch: 23\n",
      "train/acc 96.845\n",
      "train/loss 0.09469286900863591\n",
      " Test acc 95.2\n",
      "largest SV of Conv2d_0 1.0821516513824463\n",
      "\n",
      "Epoch: 24\n",
      "train/acc 96.94833333333334\n",
      "train/loss 0.09198517771338476\n",
      " Test acc 94.61\n",
      "largest SV of Conv2d_0 1.087164282798767\n",
      "\n",
      "Epoch: 25\n",
      "train/acc 96.96333333333334\n",
      "train/loss 0.09220025618510969\n",
      " Test acc 95.33\n",
      "largest SV of Conv2d_0 1.087702989578247\n",
      "\n",
      "Epoch: 26\n",
      "train/acc 97.06\n",
      "train/loss 0.0885567337846451\n",
      " Test acc 95.5\n",
      "largest SV of Conv2d_0 1.0756340026855469\n",
      "\n",
      "Epoch: 27\n",
      "train/acc 97.06666666666666\n",
      "train/loss 0.08727017065672986\n",
      " Test acc 95.25\n",
      "largest SV of Conv2d_0 1.0833698511123657\n",
      "\n",
      "Epoch: 28\n",
      "train/acc 97.14833333333333\n",
      "train/loss 0.08435196868344538\n",
      " Test acc 95.37\n",
      "largest SV of Conv2d_0 1.0732477903366089\n",
      "\n",
      "Epoch: 29\n",
      "train/acc 97.26166666666667\n",
      "train/loss 0.08521358687271759\n",
      " Test acc 95.43\n",
      "largest SV of Conv2d_0 1.079461932182312\n",
      "\n",
      "Epoch: 30\n",
      "train/acc 97.16833333333334\n",
      "train/loss 0.08497338926296498\n",
      " Test acc 94.69\n",
      "largest SV of Conv2d_0 1.0843427181243896\n",
      "\n",
      "Epoch: 31\n",
      "train/acc 97.36333333333333\n",
      "train/loss 0.08049707527933662\n",
      " Test acc 95.21\n",
      "largest SV of Conv2d_0 1.0693858861923218\n",
      "\n",
      "Epoch: 32\n",
      "train/acc 97.39666666666666\n",
      "train/loss 0.08000062139375187\n",
      " Test acc 95.51\n",
      "largest SV of Conv2d_0 1.077267050743103\n",
      "\n",
      "Epoch: 33\n",
      "train/acc 97.255\n",
      "train/loss 0.08239571307736165\n",
      " Test acc 95.29\n",
      "largest SV of Conv2d_0 1.100037932395935\n",
      "\n",
      "Epoch: 34\n",
      "train/acc 97.37166666666667\n",
      "train/loss 0.07935503958813798\n",
      " Test acc 94.82\n",
      "largest SV of Conv2d_0 1.0854334831237793\n",
      "\n",
      "Epoch: 35\n",
      "train/acc 97.50166666666667\n",
      "train/loss 0.07637783164567531\n",
      " Test acc 95.44\n",
      "largest SV of Conv2d_0 1.0833338499069214\n",
      "\n",
      "Epoch: 36\n",
      "train/acc 97.54333333333334\n",
      "train/loss 0.07528548274657873\n",
      " Test acc 95.19\n",
      "largest SV of Conv2d_0 1.0759222507476807\n",
      "\n",
      "Epoch: 37\n",
      "train/acc 97.54666666666667\n",
      "train/loss 0.0754507220566654\n",
      " Test acc 94.68\n",
      "largest SV of Conv2d_0 1.0879191160202026\n",
      "\n",
      "Epoch: 38\n",
      "train/acc 97.58833333333334\n",
      "train/loss 0.07412220481068277\n",
      " Test acc 95.24\n",
      "largest SV of Conv2d_0 1.0821731090545654\n",
      "\n",
      "Epoch: 39\n",
      "train/acc 97.51166666666667\n",
      "train/loss 0.07440494282889976\n",
      " Test acc 94.74\n",
      "largest SV of Conv2d_0 1.0803664922714233\n",
      "\n",
      "Epoch: 40\n",
      "train/acc 98.24166666666666\n",
      "train/loss 0.05851349656555508\n",
      " Test acc 95.94\n",
      "largest SV of Conv2d_0 1.0228629112243652\n",
      "\n",
      "Epoch: 41\n",
      "train/acc 98.43\n",
      "train/loss 0.05528998425178754\n",
      " Test acc 95.71\n",
      "largest SV of Conv2d_0 1.0119394063949585\n",
      "\n",
      "Epoch: 42\n",
      "train/acc 98.435\n",
      "train/loss 0.053797326003040456\n",
      " Test acc 95.85\n",
      "largest SV of Conv2d_0 1.0093642473220825\n",
      "\n",
      "Epoch: 43\n",
      "train/acc 98.475\n",
      "train/loss 0.05336806349067101\n",
      " Test acc 95.74\n",
      "largest SV of Conv2d_0 1.011635661125183\n",
      "\n",
      "Epoch: 44\n",
      "train/acc 98.52166666666666\n",
      "train/loss 0.052783928605030846\n",
      " Test acc 95.73\n",
      "largest SV of Conv2d_0 1.0093026161193848\n",
      "\n",
      "Epoch: 45\n",
      "train/acc 98.49833333333333\n",
      "train/loss 0.05301315540165853\n",
      " Test acc 95.9\n",
      "largest SV of Conv2d_0 1.0102499723434448\n",
      "\n",
      "Epoch: 46\n",
      "train/acc 98.56333333333333\n",
      "train/loss 0.05177052433926191\n",
      " Test acc 95.54\n",
      "largest SV of Conv2d_0 1.0090781450271606\n",
      "\n",
      "Epoch: 47\n",
      "train/acc 98.56333333333333\n",
      "train/loss 0.051581616580946996\n",
      " Test acc 95.75\n",
      "largest SV of Conv2d_0 1.0087223052978516\n",
      "\n",
      "Epoch: 48\n",
      "train/acc 98.515\n",
      "train/loss 0.052147758159556114\n",
      " Test acc 95.88\n",
      "largest SV of Conv2d_0 1.0094411373138428\n",
      "\n",
      "Epoch: 49\n",
      "train/acc 98.55\n",
      "train/loss 0.05205042304983462\n",
      " Test acc 95.78\n",
      "largest SV of Conv2d_0 1.007739782333374\n",
      "\n",
      "Epoch: 50\n",
      "train/acc 98.555\n",
      "train/loss 0.051523011844994415\n",
      " Test acc 95.86\n",
      "largest SV of Conv2d_0 1.0077202320098877\n",
      "\n",
      "Epoch: 51\n",
      "train/acc 98.57666666666667\n",
      "train/loss 0.05158338944381997\n",
      " Test acc 95.76\n",
      "largest SV of Conv2d_0 1.0093640089035034\n",
      "\n",
      "Epoch: 52\n",
      "train/acc 98.605\n",
      "train/loss 0.05113959366451703\n",
      " Test acc 95.92\n",
      "largest SV of Conv2d_0 1.0079597234725952\n",
      "\n",
      "Epoch: 53\n",
      "train/acc 98.55666666666667\n",
      "train/loss 0.05117967807010674\n",
      " Test acc 95.79\n",
      "largest SV of Conv2d_0 1.0097532272338867\n",
      "\n",
      "Epoch: 54\n",
      "train/acc 98.57666666666667\n",
      "train/loss 0.05099789789125228\n",
      " Test acc 95.64\n",
      "largest SV of Conv2d_0 1.0091478824615479\n",
      "\n",
      "Epoch: 55\n",
      "train/acc 98.575\n",
      "train/loss 0.05105977271125515\n",
      " Test acc 95.83\n",
      "largest SV of Conv2d_0 1.0091546773910522\n",
      "\n",
      "Epoch: 56\n",
      "train/acc 98.55666666666667\n",
      "train/loss 0.05037235410046031\n",
      " Test acc 95.76\n",
      "largest SV of Conv2d_0 1.008038878440857\n",
      "\n",
      "Epoch: 57\n",
      "train/acc 98.61333333333333\n",
      "train/loss 0.05040310317479662\n",
      " Test acc 95.79\n",
      "largest SV of Conv2d_0 1.0102335214614868\n",
      "\n",
      "Epoch: 58\n",
      "train/acc 98.61\n",
      "train/loss 0.050380525381755095\n",
      " Test acc 95.83\n",
      "largest SV of Conv2d_0 1.0072888135910034\n",
      "\n",
      "Epoch: 59\n",
      "train/acc 98.625\n",
      "train/loss 0.050171269653940885\n",
      " Test acc 95.74\n",
      "largest SV of Conv2d_0 1.008471131324768\n",
      "\n",
      "Epoch: 60\n",
      "train/acc 98.66666666666667\n",
      "train/loss 0.04966772079412172\n",
      " Test acc 95.72\n",
      "largest SV of Conv2d_0 1.0090113878250122\n",
      "\n",
      "Epoch: 61\n",
      "train/acc 98.605\n",
      "train/loss 0.04994800718211289\n",
      " Test acc 95.65\n",
      "largest SV of Conv2d_0 1.0068707466125488\n",
      "\n",
      "Epoch: 62\n",
      "train/acc 98.665\n",
      "train/loss 0.0498518211854451\n",
      " Test acc 95.62\n",
      "largest SV of Conv2d_0 1.0086694955825806\n",
      "\n",
      "Epoch: 63\n",
      "train/acc 98.62333333333333\n",
      "train/loss 0.04958065953264549\n",
      " Test acc 95.72\n",
      "largest SV of Conv2d_0 1.0080443620681763\n",
      "\n",
      "Epoch: 64\n",
      "train/acc 98.66166666666666\n",
      "train/loss 0.049539860776826136\n",
      " Test acc 95.64\n",
      "largest SV of Conv2d_0 1.0090051889419556\n",
      "\n",
      "Epoch: 65\n",
      "train/acc 98.64166666666667\n",
      "train/loss 0.049429946554217064\n",
      " Test acc 95.84\n",
      "largest SV of Conv2d_0 1.0063377618789673\n",
      "\n",
      "Epoch: 66\n",
      "train/acc 98.66166666666666\n",
      "train/loss 0.04900843287105245\n",
      " Test acc 95.72\n",
      "largest SV of Conv2d_0 1.0080769062042236\n",
      "\n",
      "Epoch: 67\n",
      "train/acc 98.68833333333333\n",
      "train/loss 0.04910379638279806\n",
      " Test acc 95.55\n",
      "largest SV of Conv2d_0 1.0078074932098389\n",
      "\n",
      "Epoch: 68\n",
      "train/acc 98.66666666666667\n",
      "train/loss 0.04862659862999723\n",
      " Test acc 95.69\n",
      "largest SV of Conv2d_0 1.00759756565094\n",
      "\n",
      "Epoch: 69\n",
      "train/acc 98.62166666666667\n",
      "train/loss 0.04947587352063356\n",
      " Test acc 95.71\n",
      "largest SV of Conv2d_0 1.0086991786956787\n",
      "\n",
      "Epoch: 70\n",
      "train/acc 98.64333333333333\n",
      "train/loss 0.04899653847585482\n",
      " Test acc 95.78\n",
      "largest SV of Conv2d_0 1.0091277360916138\n",
      "\n",
      "Epoch: 71\n",
      "train/acc 98.67333333333333\n",
      "train/loss 0.04895339763637926\n",
      " Test acc 95.79\n",
      "largest SV of Conv2d_0 1.0062183141708374\n",
      "\n",
      "Epoch: 72\n",
      "train/acc 98.685\n",
      "train/loss 0.04853200306619472\n",
      " Test acc 95.7\n",
      "largest SV of Conv2d_0 1.0078048706054688\n",
      "\n",
      "Epoch: 73\n",
      "train/acc 98.68666666666667\n",
      "train/loss 0.04848381912490643\n",
      " Test acc 95.55\n",
      "largest SV of Conv2d_0 1.0074899196624756\n",
      "\n",
      "Epoch: 74\n",
      "train/acc 98.69\n",
      "train/loss 0.048350716935101345\n",
      " Test acc 95.59\n",
      "largest SV of Conv2d_0 1.0079772472381592\n",
      "\n",
      "Epoch: 75\n",
      "train/acc 98.68666666666667\n",
      "train/loss 0.04837036356012196\n",
      " Test acc 95.69\n",
      "largest SV of Conv2d_0 1.0078063011169434\n",
      "\n",
      "Epoch: 76\n",
      "train/acc 98.67\n",
      "train/loss 0.04812691804927104\n",
      " Test acc 95.69\n",
      "largest SV of Conv2d_0 1.0075000524520874\n",
      "\n",
      "Epoch: 77\n",
      "train/acc 98.71666666666667\n",
      "train/loss 0.048153437314622564\n",
      " Test acc 95.67\n",
      "largest SV of Conv2d_0 1.0069783926010132\n",
      "\n",
      "Epoch: 78\n",
      "train/acc 98.71333333333334\n",
      "train/loss 0.04793672299167431\n",
      " Test acc 95.8\n",
      "largest SV of Conv2d_0 1.008089303970337\n",
      "\n",
      "Epoch: 79\n",
      "train/acc 98.715\n",
      "train/loss 0.048129211998046206\n",
      " Test acc 95.71\n",
      "largest SV of Conv2d_0 1.0076878070831299\n",
      "\n",
      "Epoch: 80\n",
      "train/acc 98.76333333333334\n",
      "train/loss 0.046435999469573434\n",
      " Test acc 95.66\n",
      "largest SV of Conv2d_0 1.006636142730713\n",
      "\n",
      "Epoch: 81\n",
      "train/acc 98.785\n",
      "train/loss 0.046221041650787345\n",
      " Test acc 95.7\n",
      "largest SV of Conv2d_0 1.0058366060256958\n",
      "\n",
      "Epoch: 82\n",
      "train/acc 98.835\n",
      "train/loss 0.046331120613239594\n",
      " Test acc 95.71\n",
      "largest SV of Conv2d_0 1.0050013065338135\n",
      "\n",
      "Epoch: 83\n",
      "train/acc 98.81333333333333\n",
      "train/loss 0.04631513335517665\n",
      " Test acc 95.72\n",
      "largest SV of Conv2d_0 1.0051544904708862\n",
      "\n",
      "Epoch: 84\n",
      "train/acc 98.79666666666667\n",
      "train/loss 0.04618357526245656\n",
      " Test acc 95.72\n",
      "largest SV of Conv2d_0 1.0048961639404297\n",
      "\n",
      "Epoch: 85\n",
      "train/acc 98.8\n",
      "train/loss 0.04641501117807462\n",
      " Test acc 95.68\n",
      "largest SV of Conv2d_0 1.0050866603851318\n",
      "\n",
      "Epoch: 86\n",
      "train/acc 98.835\n",
      "train/loss 0.045873638520489875\n",
      " Test acc 95.72\n",
      "largest SV of Conv2d_0 1.004621982574463\n",
      "\n",
      "Epoch: 87\n",
      "train/acc 98.81333333333333\n",
      "train/loss 0.046040683158679305\n",
      " Test acc 95.74\n",
      "largest SV of Conv2d_0 1.004784345626831\n",
      "\n",
      "Epoch: 88\n",
      "train/acc 98.79333333333334\n",
      "train/loss 0.04628636342967783\n",
      " Test acc 95.73\n",
      "largest SV of Conv2d_0 1.004953145980835\n",
      "\n",
      "Epoch: 89\n",
      "train/acc 98.82666666666667\n",
      "train/loss 0.04598130151303783\n",
      " Test acc 95.69\n",
      "largest SV of Conv2d_0 1.0042896270751953\n",
      "\n",
      "Epoch: 90\n",
      "train/acc 98.83\n",
      "train/loss 0.04618492531878099\n",
      " Test acc 95.74\n",
      "largest SV of Conv2d_0 1.0042109489440918\n",
      "\n",
      "Epoch: 91\n",
      "train/acc 98.825\n",
      "train/loss 0.04587190824626351\n",
      " Test acc 95.71\n",
      "largest SV of Conv2d_0 1.0039197206497192\n",
      "\n",
      "Epoch: 92\n",
      "train/acc 98.81333333333333\n",
      "train/loss 0.04589765589199722\n",
      " Test acc 95.67\n",
      "largest SV of Conv2d_0 1.0041393041610718\n",
      "\n",
      "Epoch: 93\n",
      "train/acc 98.83333333333333\n",
      "train/loss 0.04592129205470718\n",
      " Test acc 95.68\n",
      "largest SV of Conv2d_0 1.0038727521896362\n",
      "\n",
      "Epoch: 94\n",
      "train/acc 98.82333333333334\n",
      "train/loss 0.0456323822789482\n",
      " Test acc 95.69\n",
      "largest SV of Conv2d_0 1.0031378269195557\n",
      "\n",
      "Epoch: 95\n",
      "train/acc 98.80166666666666\n",
      "train/loss 0.046123696421620564\n",
      " Test acc 95.71\n",
      "largest SV of Conv2d_0 1.0033267736434937\n",
      "\n",
      "Epoch: 96\n",
      "train/acc 98.815\n",
      "train/loss 0.04613313541960106\n",
      " Test acc 95.69\n",
      "largest SV of Conv2d_0 1.003515362739563\n",
      "\n",
      "Epoch: 97\n",
      "train/acc 98.835\n",
      "train/loss 0.04545090467269931\n",
      " Test acc 95.69\n",
      "largest SV of Conv2d_0 1.003522276878357\n",
      "\n",
      "Epoch: 98\n",
      "train/acc 98.84166666666667\n",
      "train/loss 0.0456764244261994\n",
      " Test acc 95.72\n",
      "largest SV of Conv2d_0 1.0037339925765991\n",
      "\n",
      "Epoch: 99\n",
      "train/acc 98.795\n",
      "train/loss 0.04602944869786374\n",
      " Test acc 95.67\n",
      "largest SV of Conv2d_0 1.003943681716919\n",
      "\n",
      "Epoch: 100\n",
      "train/acc 98.80666666666667\n",
      "train/loss 0.045825851950119297\n",
      " Test acc 95.71\n",
      "largest SV of Conv2d_0 1.0037881135940552\n",
      "\n",
      "Epoch: 101\n",
      "train/acc 98.82833333333333\n",
      "train/loss 0.04576668972526786\n",
      " Test acc 95.69\n",
      "largest SV of Conv2d_0 1.003616213798523\n",
      "\n",
      "Epoch: 102\n",
      "train/acc 98.82166666666667\n",
      "train/loss 0.04599959010294061\n",
      " Test acc 95.72\n",
      "largest SV of Conv2d_0 1.0034301280975342\n",
      "\n",
      "Epoch: 103\n",
      "train/acc 98.825\n",
      "train/loss 0.046179344643280704\n",
      " Test acc 95.67\n",
      "largest SV of Conv2d_0 1.0035873651504517\n",
      "\n",
      "Epoch: 104\n",
      "train/acc 98.82333333333334\n",
      "train/loss 0.04625305784806641\n",
      " Test acc 95.74\n",
      "largest SV of Conv2d_0 1.0036760568618774\n",
      "\n",
      "Epoch: 105\n",
      "train/acc 98.82166666666667\n",
      "train/loss 0.04578141483869443\n",
      " Test acc 95.69\n",
      "largest SV of Conv2d_0 1.0037486553192139\n",
      "\n",
      "Epoch: 106\n",
      "train/acc 98.80666666666667\n",
      "train/loss 0.0458247506780538\n",
      " Test acc 95.69\n",
      "largest SV of Conv2d_0 1.0039124488830566\n",
      "\n",
      "Epoch: 107\n",
      "train/acc 98.765\n",
      "train/loss 0.045954289480741976\n",
      " Test acc 95.66\n",
      "largest SV of Conv2d_0 1.004110336303711\n",
      "\n",
      "Epoch: 108\n",
      "train/acc 98.825\n",
      "train/loss 0.04565262495835961\n",
      " Test acc 95.7\n",
      "largest SV of Conv2d_0 1.003631353378296\n",
      "\n",
      "Epoch: 109\n",
      "train/acc 98.845\n",
      "train/loss 0.04568334531261405\n",
      " Test acc 95.71\n",
      "largest SV of Conv2d_0 1.003889560699463\n",
      "\n",
      "Epoch: 110\n",
      "train/acc 98.79833333333333\n",
      "train/loss 0.04596596176841302\n",
      " Test acc 95.73\n",
      "largest SV of Conv2d_0 1.0033560991287231\n",
      "\n",
      "Epoch: 111\n",
      "train/acc 98.82833333333333\n",
      "train/loss 0.04589502373015258\n",
      " Test acc 95.72\n",
      "largest SV of Conv2d_0 1.003309965133667\n",
      "\n",
      "Epoch: 112\n",
      "train/acc 98.79833333333333\n",
      "train/loss 0.0458723910764527\n",
      " Test acc 95.74\n",
      "largest SV of Conv2d_0 1.0034903287887573\n",
      "\n",
      "Epoch: 113\n",
      "train/acc 98.82833333333333\n",
      "train/loss 0.04561736908699594\n",
      " Test acc 95.69\n",
      "largest SV of Conv2d_0 1.003326654434204\n",
      "\n",
      "Epoch: 114\n",
      "train/acc 98.82333333333334\n",
      "train/loss 0.04570465221969303\n",
      " Test acc 95.72\n",
      "largest SV of Conv2d_0 1.0033475160598755\n",
      "\n",
      "Epoch: 115\n",
      "train/acc 98.81\n",
      "train/loss 0.0456363817950937\n",
      " Test acc 95.69\n",
      "largest SV of Conv2d_0 1.0036556720733643\n",
      "\n",
      "Epoch: 116\n",
      "train/acc 98.83666666666667\n",
      "train/loss 0.04591373166343424\n",
      " Test acc 95.73\n",
      "largest SV of Conv2d_0 1.0037379264831543\n",
      "\n",
      "Epoch: 117\n",
      "train/acc 98.805\n",
      "train/loss 0.046016902466223183\n",
      " Test acc 95.76\n",
      "largest SV of Conv2d_0 1.0038293600082397\n",
      "\n",
      "Epoch: 118\n",
      "train/acc 98.83\n",
      "train/loss 0.04549237833554938\n",
      " Test acc 95.7\n",
      "largest SV of Conv2d_0 1.0040323734283447\n",
      "\n",
      "Epoch: 119\n",
      "train/acc 98.83666666666667\n",
      "train/loss 0.045457060101316935\n",
      " Test acc 95.69\n",
      "largest SV of Conv2d_0 1.0041296482086182\n"
     ]
    }
   ],
   "source": [
    "seed_list = [10**i for i in range(5)]\n",
    "seed = seed_list[0]\n",
    "\n",
    "epochs = 120\n",
    "\n",
    "best_acc = 0  # best test accuracy\n",
    "count_setp = 0\n",
    "\n",
    "seed_val = seed\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "random.seed(seed_val)\n",
    "\n",
    "trainset = get_dataset('mnist', 'train')\n",
    "testset = get_dataset('mnist', 'test')\n",
    "trainloader = torch.utils.data.DataLoader(trainset, shuffle=True, batch_size=128, num_workers=1)\n",
    "testloader = torch.utils.data.DataLoader(testset, shuffle=False, batch_size=128, num_workers=1)\n",
    "\n",
    "##### settings of the convolutional layer:\n",
    "kernel_size = 3\n",
    "stride = 1\n",
    "padding = 1\n",
    "dilation = 1\n",
    "lin_layer = None\n",
    "padding_mode = 'reflect'\n",
    "\n",
    "method = 'fastclip'  ### ---> choose one of these clipping methods = ['fastclip', 'nsedghi', 'miyato', 'gouk', 'lip4conv', 'orig']\n",
    "### orig: original model without clipping, \n",
    "### fastclip: our method,\n",
    "### lip4conv: Delattre et al. (2023),\n",
    "### nsedghi: Senderovich et al. (2022),\n",
    "### gouk: Gouk et al. (2021),\n",
    "### miyato: Miyato et al. (2018)\n",
    "\n",
    "results_df = main(trainloader, testloader, \n",
    "                    method=method, epochs=epochs, kernel_size=kernel_size, \n",
    "                    stride=stride, padding=padding, dilation=dilation, \n",
    "                    padding_mode=padding_mode, lin_layer=lin_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    tr_loss     tr_acc   ts_loss  ts_acc        SV\n",
      "0  0.403339  87.070000  0.230342   92.97  1.893099\n",
      "1  0.239349  92.315000  0.183566   94.47  1.235358\n",
      "2  0.195935  93.801667  0.198700   93.57  1.093779\n",
      "3  0.175395  94.376667  0.193428   93.93  1.079450\n",
      "4  0.165007  94.718333  0.178349   94.23  1.080974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5bf27328c0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(results_df.head())\n",
    "plt.plot(results_df.index, results_df['SV'], label='Spectral Norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-91b7584a2265b1f5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-91b7584a2265b1f5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir simpleConv/fastclip_model_k3_p0_st1_di1_pad_reflect/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastclip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
